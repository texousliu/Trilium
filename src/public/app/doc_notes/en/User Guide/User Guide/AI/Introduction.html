<figure class="image image_resized" style="width:63.68%;">
  <img style="aspect-ratio:1363/1364;" src="Introduction_image.png" width="1363"
  height="1364">
  <figcaption>An example chat with an LLM</figcaption>
</figure>
<p>The AI / LLM features within Trilium Notes are designed to allow you to
  interact with your Notes in a variety of ways, using as many of the major
  providers as we can support.&nbsp;</p>
<p>In addition to being able to send chats to LLM providers such as OpenAI,
  Anthropic, and Ollama - we also support agentic tool calling, and embeddings.</p>
<p>The quickest way to get started is to navigate to the “AI/LLM” settings:</p>
<figure
class="image image_resized" style="width:74.04%;">
  <img style="aspect-ratio:1916/1906;" src="5_Introduction_image.png" width="1916"
  height="1906">
  </figure>
  <p>Enable the feature:</p>
  <figure class="image image_resized" style="width:82.82%;">
    <img style="aspect-ratio:1911/997;" src="1_Introduction_image.png" width="1911"
    height="997">
  </figure>
  
<h2>Embeddings</h2>
  <p><strong>Embeddings</strong> are important as it allows us to have an compact
    AI “summary” (it's not human readable text) of each of your Notes, that
    we can then perform mathematical functions on (such as cosine similarity)
    to smartly figure out which Notes to send as context to the LLM when you're
    chatting, among other useful functions.</p>
  <p>You will then need to set up the AI “provider” that you wish to use to
    create the embeddings for your Notes. Currently OpenAI, Voyage AI, and
    Ollama are supported providers for embedding generation.</p>
  <p>In the following example, we're going to use our self-hosted Ollama instance
    to create the embeddings for our Notes. You can see additional documentation
    about installing your own Ollama locally in&nbsp;<a class="reference-link"
    href="#root/_help_vvUCN7FDkq7G">Installing Ollama</a>.</p>
  <p>To see what embedding models Ollama has available, you can check out
    <a
    href="https://ollama.com/search?c=embedding">this search</a>on their website, and then <code>pull</code> whichever one
      you want to try out. As of 4/15/25, my personal favorite is <code>mxbai-embed-large</code>.</p>
  <p>First, we'll need to select the Ollama provider from the tabs of providers,
    then we will enter in the Base URL for our Ollama. Since our Ollama is
    running on our local machine, our Base URL is <code>http://localhost:11434</code>.
    We will then hit the “refresh” button to have it fetch our models:</p>
  <figure
  class="image image_resized" style="width:82.28%;">
    <img style="aspect-ratio:1912/1075;" src="4_Introduction_image.png" width="1912"
    height="1075">
    </figure>
    <p>When selecting the dropdown for the “Embedding Model”, embedding models
      should be at the top of the list, separated by regular chat models with
      a horizontal line, as seen below:</p>
    <figure class="image image_resized"
    style="width:61.73%;">
      <img style="aspect-ratio:1232/959;" src="8_Introduction_image.png" width="1232"
      height="959">
    </figure>
    <p>After selecting an embedding model, embeddings should automatically begin
      to be generated by checking the embedding statistics at the top of the
      “AI/LLM” settings panel:</p>
    <figure class="image image_resized" style="width:67.06%;">
      <img style="aspect-ratio:1333/499;" src="7_Introduction_image.png" width="1333"
      height="499">
    </figure>
    <p>If you don't see any embeddings being created, you will want to scroll
      to the bottom of the settings, and hit “Recreate All Embeddings”:</p>
    <figure
    class="image image_resized" style="width:65.69%;">
      <img style="aspect-ratio:1337/1490;" src="3_Introduction_image.png" width="1337"
      height="1490">
      </figure>
      <p>Creating the embeddings will take some time, and will be regenerated when
        a Note is created, updated, or deleted (removed).</p>
      <p>If for some reason you choose to change your embedding provider, or the
        model used, you'll need to recreate all embeddings.</p>
      <h2>Tools</h2>
      <p>Tools are essentially functions that we provide to the various LLM providers,
        and then LLMs can respond in a specific format that tells us what tool
        function and parameters they would like to invoke. We then execute these
        tools, and provide it as additional context in the Chat conversation.&nbsp;</p>
      <p>These are the tools that currently exist, and will certainly be updated
        to be more effectively (and even more to be added!):</p>
      <ul>
        <li><code>search_notes</code>
          <ul>
            <li>Semantic search</li>
          </ul>
        </li>
        <li><code>keyword_search</code>
          <ul>
            <li>Keyword-based search</li>
          </ul>
        </li>
        <li><code>attribute_search</code>
          <ul>
            <li>Attribute-specific search</li>
          </ul>
        </li>
        <li><code>search_suggestion</code>
          <ul>
            <li>Search syntax helper</li>
          </ul>
        </li>
        <li><code>read_note</code>
          <ul>
            <li>Read note content (helps the LLM read Notes)</li>
          </ul>
        </li>
        <li><code>create_note</code>
          <ul>
            <li>Create a Note</li>
          </ul>
        </li>
        <li><code>update_note</code>
          <ul>
            <li>Update a Note</li>
          </ul>
        </li>
        <li><code>manage_attributes</code>
          <ul>
            <li>Manage attributes on a Note</li>
          </ul>
        </li>
        <li><code>manage_relationships</code>
          <ul>
            <li>Manage the various relationships between Notes</li>
          </ul>
        </li>
        <li><code>extract_content</code>
          <ul>
            <li>Used to smartly extract content from a Note</li>
          </ul>
        </li>
        <li><code>calendar_integration</code>
          <ul>
            <li>Used to find date notes, create date notes, get the daily note, etc.</li>
          </ul>
        </li>
      </ul>
      <p>When Tools are executed within your Chat, you'll see output like the following:</p>
      <figure
      class="image image_resized" style="width:66.88%;">
        <img style="aspect-ratio:1372/1591;" src="6_Introduction_image.png" width="1372"
        height="1591">
        </figure>
        <p>You don't need to tell the LLM to execute a certain tool, it should “smartly”
          call tools and automatically execute them as needed.</p>
        <h2>Overview</h2>
        <p>Now that you know about embeddings and tools, you can just go ahead and
          use the “Chat with Notes” button, where you can go ahead and start chatting!:</p>
        <figure
        class="image image_resized" style="width:60.77%;">
          <img style="aspect-ratio:1378/539;" src="2_Introduction_image.png" width="1378"
          height="539">
          </figure>
          <p>If you don't see the “Chat with Notes” button on your side launchbar,
            you might need to move it from the “Available Launchers” section to the
            “Visible Launchers” section:</p>
          <figure class="image image_resized" style="width:69.81%;">
            <img style="aspect-ratio:1765/1287;" src="9_Introduction_image.png" width="1765"
            height="1287">
          </figure>