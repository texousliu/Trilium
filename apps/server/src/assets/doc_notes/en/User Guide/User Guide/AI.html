<figure class="image image_resized" style="width:63.68%;">
  <img style="aspect-ratio:1363/1364;" src="AI_image.png"
  width="1363" height="1364">
  <figcaption>An example chat with an LLM</figcaption>
</figure>
<p>The AI / LLM features within Trilium Notes are designed to allow you to
  interact with your Notes in a variety of ways, using as many of the major
  providers as we can support.&nbsp;</p>
<p>In addition to being able to send chats to LLM providers such as OpenAI,
  Anthropic, and Ollama - we also support agentic tool calling, and embeddings.</p>
<p>The quickest way to get started is to navigate to the “AI/LLM” settings:</p>
<figure
class="image image_resized" style="width:74.04%;">
  <img style="aspect-ratio:1916/1906;" src="5_AI_image.png"
  width="1916" height="1906">
  </figure>
  <p>Enable the feature:</p>
  <figure class="image image_resized" style="width:82.82%;">
    <img style="aspect-ratio:1911/997;" src="1_AI_image.png"
    width="1911" height="997">
  </figure>
  
<h2>Embeddings</h2>
  <p><strong>Embeddings</strong> are important as it allows us to have an compact
    AI “summary” (it's not human readable text) of each of your Notes, that
    we can then perform mathematical functions on (such as cosine similarity)
    to smartly figure out which Notes to send as context to the LLM when you're
    chatting, among other useful functions.</p>
  <p>You will then need to set up the AI “provider” that you wish to use to
    create the embeddings for your Notes. Currently OpenAI, Voyage AI, and
    Ollama are supported providers for embedding generation.</p>
  <p>In the following example, we're going to use our self-hosted Ollama instance
    to create the embeddings for our Notes. You can see additional documentation
    about installing your own Ollama locally in&nbsp;<a class="reference-link"
    href="#root/_help_vvUCN7FDkq7G">Installing Ollama</a>.</p>
  <p>To see what embedding models Ollama has available, you can check out
    <a
    href="https://ollama.com/search?c=embedding">this search</a>on their website, and then <code spellcheck="false">pull</code> whichever
      one you want to try out. A popular choice is <code spellcheck="false">mxbai-embed-large</code>.</p>
  <p>First, we'll need to select the Ollama provider from the tabs of providers,
    then we will enter in the Base URL for our Ollama. Since our Ollama is
    running on our local machine, our Base URL is <code spellcheck="false">http://localhost:11434</code>.
    We will then hit the “refresh” button to have it fetch our models:</p>
  <figure
  class="image image_resized" style="width:82.28%;">
    <img style="aspect-ratio:1912/1075;" src="4_AI_image.png"
    width="1912" height="1075">
    </figure>
    <p>When selecting the dropdown for the “Embedding Model”, embedding models
      should be at the top of the list, separated by regular chat models with
      a horizontal line, as seen below:</p>
    <figure class="image image_resized"
    style="width:61.73%;">
      <img style="aspect-ratio:1232/959;" src="8_AI_image.png"
      width="1232" height="959">
    </figure>
    <p>After selecting an embedding model, embeddings should automatically begin
      to be generated by checking the embedding statistics at the top of the
      “AI/LLM” settings panel:</p>
    <figure class="image image_resized" style="width:67.06%;">
      <img style="aspect-ratio:1333/499;" src="7_AI_image.png"
      width="1333" height="499">
    </figure>
    <p>If you don't see any embeddings being created, you will want to scroll
      to the bottom of the settings, and hit “Recreate All Embeddings”:</p>
    <figure
    class="image image_resized" style="width:65.69%;">
      <img style="aspect-ratio:1337/1490;" src="3_AI_image.png"
      width="1337" height="1490">
      </figure>
      <p>Creating the embeddings will take some time, and will be regenerated when
        a Note is created, updated, or deleted (removed).</p>
      <p>If for some reason you choose to change your embedding provider, or the
        model used, you'll need to recreate all embeddings.</p>
      <h2>Tools</h2>
      <p>Tools are essentially functions that we provide to the various LLM providers,
        and then LLMs can respond in a specific format that tells us what tool
        function and parameters they would like to invoke. We then execute these
        tools, and provide it as additional context in the Chat conversation.&nbsp;</p>
      <p>These are the tools that currently exist, and will certainly be updated
        to be more effectively (and even more to be added!):</p>
      <ul>
        <li><code spellcheck="false">search_notes</code>
          <ul>
            <li>Semantic search</li>
          </ul>
        </li>
        <li><code spellcheck="false">keyword_search</code>
          <ul>
            <li>Keyword-based search</li>
          </ul>
        </li>
        <li><code spellcheck="false">attribute_search</code>
          <ul>
            <li>Attribute-specific search</li>
          </ul>
        </li>
        <li><code spellcheck="false">search_suggestion</code>
          <ul>
            <li>Search syntax helper</li>
          </ul>
        </li>
        <li><code spellcheck="false">read_note</code>
          <ul>
            <li>Read note content (helps the LLM read Notes)</li>
          </ul>
        </li>
        <li><code spellcheck="false">create_note</code>
          <ul>
            <li>Create a Note</li>
          </ul>
        </li>
        <li><code spellcheck="false">update_note</code>
          <ul>
            <li>Update a Note</li>
          </ul>
        </li>
        <li><code spellcheck="false">manage_attributes</code>
          <ul>
            <li>Manage attributes on a Note</li>
          </ul>
        </li>
        <li><code spellcheck="false">manage_relationships</code>
          <ul>
            <li>Manage the various relationships between Notes</li>
          </ul>
        </li>
        <li><code spellcheck="false">extract_content</code>
          <ul>
            <li>Used to smartly extract content from a Note</li>
          </ul>
        </li>
        <li><code spellcheck="false">calendar_integration</code>
          <ul>
            <li>Used to find date notes, create date notes, get the daily note, etc.</li>
          </ul>
        </li>
      </ul>
      <p>When Tools are executed within your Chat, you'll see output like the following:</p>
      <figure
      class="image image_resized" style="width:66.88%;">
        <img style="aspect-ratio:1372/1591;" src="6_AI_image.png"
        width="1372" height="1591">
        </figure>
        <p>You don't need to tell the LLM to execute a certain tool, it should “smartly”
          call tools and automatically execute them as needed.</p>
        <h2>Overview</h2>
        <p>To start, simply press the <em>Chat with Notes</em> button in the&nbsp;
          <a
          class="reference-link" href="#root/_help_xYmIYSP6wE3F">Launch Bar</a>.</p>
        <figure class="image image_resized" style="width:60.77%;">
          <img style="aspect-ratio:1378/539;" src="2_AI_image.png"
          width="1378" height="539">
        </figure>
        <p>If you don't see the button in the&nbsp;<a class="reference-link" href="#root/_help_xYmIYSP6wE3F">Launch Bar</a>,
          you might need to move it from the <em>Available Launchers</em> section to
          the <em>Visible Launchers</em> section:</p>
        <figure class="image image_resized"
        style="width:69.81%;">
          <img style="aspect-ratio:1765/1287;" src="9_AI_image.png"
          width="1765" height="1287">
        </figure>